{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e281c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dữ liệu sau tiền xử lý ---\n",
      "D1: ['apple', 'macbook'] (Số từ: 2)\n",
      "D2: ['microsoft', 'surface'] (Số từ: 2)\n",
      "D3: ['apple', 'microsoft'] (Số từ: 2)\n",
      "\n",
      "Từ vựng (V): ['apple', 'macbook', 'microsoft', 'surface']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Tải danh sách Stop Words tiếng Anh (chỉ cần chạy lần đầu)\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# 1. DỮ LIỆU ĐẦU VÀO (Corpus)\n",
    "documents = [\n",
    "    \"Apple announces a new MacBook.\",      # D1\n",
    "    \"Microsoft announces a new Surface.\",   # D2\n",
    "    \"Apple and Microsoft are rivals.\"       # D3\n",
    "]\n",
    "\n",
    "# Danh sách Stop Words tiếng Anh chuẩn (lấy từ NLTK)\n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "# Thêm Stop Words ngữ cảnh (các từ không phân biệt chủ đề)\n",
    "CUSTOM_STOP_WORDS = ['announces', 'new', 'rivals', 'a', 'are', 'and']\n",
    "FINAL_STOP_WORDS = set(ENGLISH_STOP_WORDS + CUSTOM_STOP_WORDS)\n",
    "\n",
    "\n",
    "# 1. Hàm tiền xử lý: Chuẩn hóa, loại bỏ dấu câu và lọc Stop Words\n",
    "def preprocess(doc):\n",
    "    \n",
    "    # 1.1. Chuẩn hóa về chữ thường (Đầu tiên!)\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # 1.2. Loại bỏ Dấu câu/Ký tự đặc biệt\n",
    "    # [^a-z\\s] loại bỏ MỌI KÝ TỰ KHÔNG phải là chữ thường (a-z) hoặc khoảng trắng (\\s).\n",
    "    doc = re.sub(r'[^a-z\\s]', '', doc) \n",
    "    \n",
    "    # 1.3. Tách từ (Tokenize)\n",
    "    tokens = doc.split()\n",
    "    \n",
    "    # 1.4. Lọc Stop Words\n",
    "    return [word for word in tokens if word not in FINAL_STOP_WORDS]\n",
    "\n",
    "# Thực hiện tiền xử lý\n",
    "corpus = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Số lượng tài liệu N\n",
    "N = len(corpus) \n",
    "\n",
    "print(\"--- Dữ liệu sau tiền xử lý ---\")\n",
    "for i, doc in enumerate(corpus):\n",
    "    print(f\"D{i+1}: {doc} (Số từ: {len(doc)})\")\n",
    "\n",
    "# Tạo tập hợp các từ vựng duy nhất (Vocabulary)\n",
    "vocabulary = sorted(list(set(word for doc in corpus for word in doc)))\n",
    "print(f\"\\nTừ vựng (V): {vocabulary}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2f544",
   "metadata": {},
   "source": [
    "# **Bước 2: Tính TF (Term Frequency)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0baf431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MA TRẬN TF ---\n",
      "            D1   D2   D3\n",
      "apple      0.5  0.0  0.5\n",
      "macbook    0.5  0.0  0.0\n",
      "microsoft  0.0  0.5  0.5\n",
      "surface    0.0  0.5  0.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Hàm tính TF\n",
    "def calculate_tf(corpus, vocabulary): # Định nghĩa hàm tính TF, nhận vào tập dữ liệu (corpus) và danh sách từ vựng.\n",
    "    tf_matrix = {}\n",
    "# Khởi tạo từ điển rỗng để lưu toàn bộ kết quả TF cho tất cả tài liệu.\n",
    "    \n",
    "    for i, doc in enumerate(corpus): # Tạo tên ID cho tài liệu hiện tại\n",
    "        doc_id = f'D{i+1}'\n",
    "        doc_length = len(doc)\n",
    "        tf_scores = {}      # Khởi tạo từ điển rỗng để đếm số lần xuất hiện thô của từ trong tài liệu này.\n",
    "        \n",
    "        # Đếm tần suất\n",
    "        for word in doc:\n",
    "            tf_scores[word] = tf_scores.get(word, 0) + 1\n",
    "            \n",
    "        # Tính TF\n",
    "        for word in vocabulary:\n",
    "            count = tf_scores.get(word, 0)\n",
    "            tf_matrix.setdefault(word, {})[doc_id] = count / doc_length # Tính TF và lưu vào ma trận\n",
    "            \n",
    "    return pd.DataFrame(tf_matrix).T.fillna(0) # Chuyển thành DataFrame để hiển thị đẹp hơn\n",
    "\n",
    "tf_df = calculate_tf(corpus, vocabulary)        # Gọi hàm để tính TF và lưu kết quả vào biến tf_df.\n",
    "\n",
    "print(\"--- MA TRẬN TF ---\")\n",
    "print(tf_df)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209c9ab",
   "metadata": {},
   "source": [
    "# **Bước 3: Tính IDF (Inverse Document Frequency)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "985cdfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VECTOR IDF ---\n",
      "apple        0.176091\n",
      "macbook      0.477121\n",
      "microsoft    0.176091\n",
      "surface      0.477121\n",
      "Name: IDF, dtype: float64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 3. Hàm tính IDF\n",
    "def calculate_idf(corpus, vocabulary, N):\n",
    "    df_scores = {} # Document Frequency: Số tài liệu chứa từ t\n",
    "    \n",
    "    # Tính DF\n",
    "    for word in vocabulary:\n",
    "        # Đếm số tài liệu chứa từ 'word'\n",
    "        doc_count = sum(1 for doc in corpus if word in doc)\n",
    "        df_scores[word] = doc_count\n",
    "\n",
    "    # Tính IDF\n",
    "    idf_scores = {}\n",
    "    for word, df in df_scores.items():\n",
    "        # Công thức IDF\n",
    "        # np.log10(N / df)\n",
    "        idf_scores[word] = np.log10(N / df)\n",
    "        \n",
    "    return pd.Series(idf_scores, name='IDF')\n",
    "\n",
    "idf_series = calculate_idf(corpus, vocabulary, N)\n",
    "\n",
    "print(\"--- VECTOR IDF ---\")\n",
    "print(idf_series)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce74609",
   "metadata": {},
   "source": [
    "# **Bước 4: Tính TF-IDF và Ma trận Đặc trưng**\n",
    "TF-IDF là tích của TF và IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d48f8561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MA TRẬN TF-IDF (TRỌNG SỐ CUỐI CÙNG) ---\n",
      "               D1      D2     D3\n",
      "apple      0.0880  0.0000  0.088\n",
      "macbook    0.2386  0.0000  0.000\n",
      "microsoft  0.0000  0.0880  0.088\n",
      "surface    0.0000  0.2386  0.000\n",
      "--------------------------------------------------\n",
      "--- PHÂN TÍCH KẾT QUẢ ---\n",
      "Tài liệu D1:\n",
      "  Trọng số cao nhất: 0.2386\n",
      "  Các từ khóa phân biệt (bằng trọng số): ['macbook']\n",
      "-------------------------\n",
      "Tài liệu D2:\n",
      "  Trọng số cao nhất: 0.2386\n",
      "  Các từ khóa phân biệt (bằng trọng số): ['surface']\n",
      "-------------------------\n",
      "Tài liệu D3:\n",
      "  Trọng số cao nhất: 0.0880\n",
      "  Các từ khóa phân biệt (bằng trọng số): ['apple', 'microsoft']\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. Tính TF-IDF\n",
    "# Nhân Ma trận TF với Vector IDF (dùng numpy broadcast)\n",
    "tfidf_df = tf_df.multiply(idf_series, axis='index')\n",
    "\n",
    "print(\"--- MA TRẬN TF-IDF (TRỌNG SỐ CUỐI CÙNG) ---\")\n",
    "# Làm tròn kết quả để dễ đọc\n",
    "print(tfidf_df.round(4))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 5. PHÂN TÍCH KẾT QUẢ\n",
    "print(\"--- PHÂN TÍCH KẾT QUẢ ---\")\n",
    "\n",
    "for doc_id in tfidf_df.columns:\n",
    "    # 5.1. Tìm giá trị TF-IDF cao nhất\n",
    "    max_score = tfidf_df[doc_id].max()\n",
    "    \n",
    "    # 5.2. Lọc ra TẤT CẢ các từ có giá trị bằng với giá trị cao nhất\n",
    "    # Dùng Boolean indexing: tfidf_df[doc_id] == max_score\n",
    "    top_words = tfidf_df[doc_id][tfidf_df[doc_id] == max_score].index.tolist()\n",
    "    \n",
    "    # 5.3. In kết quả\n",
    "    print(f\"Tài liệu {doc_id}:\")\n",
    "    print(f\"  Trọng số cao nhất: {max_score:.4f}\")\n",
    "    print(f\"  Các từ khóa phân biệt (bằng trọng số): {top_words}\")\n",
    "    print(\"-\" * 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
